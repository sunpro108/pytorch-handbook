{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "什么是Pytorch\n",
    "================\n",
    "\n",
    "这是一个基于Python的科学计算软件包，面向两组受众：\n",
    "\n",
    "-  替代NumPy以使用GPU的功能\n",
    "-  深度学习研究平台，可提供最大的灵活性和速度\n",
    "\n",
    "开始吧\n",
    "---------------\n",
    "\n",
    "## 张量(Tensors)\n",
    "\n",
    "张量与NumPy的ndarrays类似，此外，  \n",
    "张量也可以在GPU上使用以加速计算。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个未初始化的5x3矩阵：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.8736e-02,  5.3810e-43, -1.8736e-02],\n",
      "        [ 5.3810e-43, -1.8736e-02,  5.3810e-43],\n",
      "        [-1.8736e-02,  5.3810e-43, -1.8736e-02],\n",
      "        [ 5.3810e-43, -1.8736e-02,  5.3810e-43],\n",
      "        [-1.8736e-02,  5.3810e-43, -1.8736e-02]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个随机初始化的矩阵：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1884, 0.9676, 0.0932],\n",
      "        [0.0237, 0.8706, 0.1165],\n",
      "        [0.8923, 0.6846, 0.2428],\n",
      "        [0.1050, 0.1057, 0.4467],\n",
      "        [0.2271, 0.8529, 0.5744]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造一个填充零且dtype long的矩阵：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接从数据创建张量：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "或基于现有张量创建张量。 这些方法将重复使用输入张量的属性，例如dtype，除非用户提供新值\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[-0.6246, -0.3308,  1.0961],\n",
      "        [-0.2643, -1.9371, -0.7324],\n",
      "        [-1.0433,  1.8659, -0.2630],\n",
      "        [-0.5869, -0.8914,  1.2099],\n",
      "        [-0.7889,  0.0762,  0.3997]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
    "print(x)                                      # result has the same size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打印它的大小：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>注</h4><p>\n",
    "\n",
    "``torch.Size`` 实际上是一个tuple，因此它支持所有tuple操作。</p></div>\n",
    "\n",
    "## 运算(Operations)\n",
    "\n",
    "运算有多种语法实现。在下面的示例中，我们将看一下加法运算。\n",
    "\n",
    "加法：语法1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5411, -0.2331,  1.4236],\n",
      "        [ 0.4124, -1.0028, -0.6942],\n",
      "        [-0.5186,  2.3691,  0.6042],\n",
      "        [-0.3107, -0.7324,  1.7120],\n",
      "        [-0.5278,  0.2224,  1.1851]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加法：语法2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5411, -0.2331,  1.4236],\n",
      "        [ 0.4124, -1.0028, -0.6942],\n",
      "        [-0.5186,  2.3691,  0.6042],\n",
      "        [-0.3107, -0.7324,  1.7120],\n",
      "        [-0.5278,  0.2224,  1.1851]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加法：提供输出张量作为参数(argument)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5411, -0.2331,  1.4236],\n",
      "        [ 0.4124, -1.0028, -0.6942],\n",
      "        [-0.5186,  2.3691,  0.6042],\n",
      "        [-0.3107, -0.7324,  1.7120],\n",
      "        [-0.5278,  0.2224,  1.1851]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加法：就地(in-place)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5411, -0.2331,  1.4236],\n",
      "        [ 0.4124, -1.0028, -0.6942],\n",
      "        [-0.5186,  2.3691,  0.6042],\n",
      "        [-0.3107, -0.7324,  1.7120],\n",
      "        [-0.5278,  0.2224,  1.1851]])\n"
     ]
    }
   ],
   "source": [
    "# adds x to y\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>注</h4><p>\n",
    "\n",
    "任何使张量就地发生变化的操作都将使用 ``_``.\n",
    "    如: ``x.copy_(y)``, ``x.t_()``, 会改变 ``x``.</p></div>\n",
    "\n",
    "您可以使用类似NumPy的标准索引来变出各种花样！\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3308, -1.9371,  1.8659, -0.8914,  0.0762])\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调整大小：如果要调整张量的大小/形状，可以使用 ``torch.view``:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果您具有一个元素张量，请使用``.item()``获取该值作为Python数字。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5033])\n",
      "0.5032538771629333\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**稍后阅读:**\n",
    "\n",
    "  [这里](https://pytorch.org/docs/torch)\n",
    "  \n",
    "包含了100多个Tensor运算，包括转置(transposing)、索引(indexing)、分割(slicing)、数学运算(mathematical operations)、线性代数(linear algebra)、随机数(random numbers)等。\n",
    "\n",
    "NumPy转换\n",
    "------------\n",
    "\n",
    "将Torch张量转换为NumPy数组，反之亦然，这十分简单。\n",
    "\n",
    "Torch张量和NumPy数组将共享其基础内存位置，并且更改一个将更改另一个。\n",
    "\n",
    "## 将Torch张量转换为NumPy数组\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看看numpy数组的值如何变化。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将NumPy数组转换为Torch张量\n",
    "\n",
    "查看更改numpy数组如何自动更改Torch Tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除CharTensor之外，CPU上的所有张量都支持转换为NumPy并转回。\n",
    "\n",
    "CUDA张量\n",
    "------------\n",
    "\n",
    "张量可以使用``.to``方法移动到任何设备上。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5033], device='cuda:0')\n",
      "tensor([1.5033], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 让我们仅在CUDA可用时运行此单元格\n",
    "# 我们将使用``torch.device``对象将张量移入和移出GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # CUDA设备对象\n",
    "    y = torch.ones_like(x, device=device)  # 在GPU上直接创建张量\n",
    "    x = x.to(device)                       # 或只使用字符串``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` 也可以一起改变dtype！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor 数据类型的转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand((4,3,5,5))\n",
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([1,2,3])\n",
    "b.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 3*b.type(torch.float32)\n",
    "c.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = [tensor([ 873.,  873.,  873., 6498., 6498., 6498., 6498., 6498., 6498., 6498.,\n",
    "         333.,  333.,  333.,  333.,  333.,  762.], device='cuda:0'), tensor([ 762.,  762.,  762., 1986., 1986., 1296., 1296., 1296.,\n",
    "1296., 1296.,\n",
    "        1248., 1248., 1248., 1074., 1074., 1074.], device='cuda:0'), tensor([1074., 1074., 2481., 2481., 2481., 2586., 2586., 2586.,\n",
    "2586., 2586.,\n",
    "        2586., 1959., 1959., 1959., 1959., 1959.], device='cuda:0'), tensor([1959.,  741.,  741.,  741., 3786., 3786., 3786., 3786.,\n",
    "3786., 3786.,\n",
    "        3786., 3786., 3786., 3786., 3786., 3786.], device='cuda:0'), tensor([3786., 3786., 1482., 1482., 1482., 1482., 7932., 7932.,\n",
    "7932., 7932.,\n",
    "        7932., 7932.,  492.,  492.,  492.,  492.], device='cuda:0'), tensor([12003., 12003., 12003.,  9849., 12003., 12498., 12498.,\n",
    "12498., 12003.,\n",
    "        12498., 14301., 14301., 12498., 11883., 12498., 12003.],\n",
    "       device='cuda:0'), tensor([12003., 12003., 11571., 12003.,  9849., 14301., 14301., 14301., 12498.,\n",
    "        12498., 12498., 46245., 46245., 46245., 46245., 46245.],\n",
    "       device='cuda:0'), tensor([46245., 46245., 46245., 46245., 46245., 46245., 32520., 46245., 46245.,\n",
    "        32520., 32520., 32520., 32520., 32520., 32520., 32520.],\n",
    "       device='cuda:0'), tensor([32520., 46245., 32520., 32520., 32520.], device='cuda:0')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = [tensor([1.9574e+07, 2.0267e+07, 1.9411e+07, 1.2925e+08, 1.2970e+08, 1.2852e+08,\n",
    "        1.3012e+08, 1.3009e+08, 1.2714e+08, 1.2911e+08, 1.6706e+07, 1.6516e+07,\n",
    "        1.6535e+07, 1.6470e+07, 1.6679e+07, 1.8653e+07], device='cuda:0'), tensor([18860952., 19184276., 18698860., 46599400.,\n",
    "46643224., 25550148.,\n",
    "        25781914., 25773074., 25954396., 25934088., 23079176., 23168144.,\n",
    "        23616194., 18726294., 18828190., 18932680.], device='cuda:0'), tensor([18338384., 18630568., 56830200., 57324084.,\n",
    "56037904., 40440044.,\n",
    "        41251344., 41957784., 40375184., 40817132., 40863160., 46335304.,\n",
    "        46845856., 48002852., 47084548., 46288180.], device='cuda:0'), tensor([47507872., 13877214., 13718280., 13645110.,\n",
    "72718256., 71402224.,\n",
    "        73005824., 71911344., 72669592., 72971872., 73501904., 72753488.,\n",
    "        73563872., 72977200., 72264112., 72596272.], device='cuda:0'), tensor([7.2655e+07, 7.2911e+07, 3.5548e+07, 3.3726e+07,\n",
    "3.5149e+07, 3.5135e+07,\n",
    "        1.3941e+08, 1.3803e+08, 1.3984e+08, 1.3990e+08, 1.3896e+08, 1.3996e+08,\n",
    "        9.2918e+06, 9.1822e+06, 8.9530e+06, 9.1907e+06], device='cuda:0'), tensor([2.1768e+08, 2.1951e+08, 2.2147e+08, 2.1355e+08,\n",
    "2.1998e+08, 2.2598e+08,\n",
    "        2.2508e+08, 2.2609e+08, 2.2547e+08, 2.2774e+08, 2.7718e+08, 2.7623e+08,\n",
    "        2.2414e+08, 1.9259e+08, 2.2424e+08, 2.2321e+08], device='cuda:0'), tensor([2.2466e+08, 2.2182e+08, 2.5323e+08, 2.2446e+08,\n",
    "2.1509e+08, 2.7583e+08,\n",
    "        2.7387e+08, 2.7341e+08, 2.2783e+08, 2.2791e+08, 2.3097e+08, 9.3252e+08,\n",
    "        9.2540e+08, 9.2587e+08, 9.1819e+08, 9.2390e+08], device='cuda:0'), tensor([9.1233e+08, 9.1744e+08, 9.4141e+08, 9.3672e+08,\n",
    "9.1867e+08, 9.2557e+08,\n",
    "        5.2621e+08, 9.2406e+08, 9.4488e+08, 5.2398e+08, 5.2425e+08, 5.2029e+08,\n",
    "        5.2010e+08, 5.2211e+08, 5.1931e+08, 5.2302e+08], device='cuda:0'), tensor([5.1897e+08, 9.1553e+08, 5.1680e+08, 5.3144e+08,\n",
    "5.2899e+08],\n",
    "       device='cuda:0')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1.9574e+07, 2.0267e+07, 1.9411e+07, 1.2925e+08, 1.2970e+08, 1.2852e+08,\n",
       "         1.3012e+08, 1.3009e+08, 1.2714e+08, 1.2911e+08, 1.6706e+07, 1.6516e+07,\n",
       "         1.6535e+07, 1.6470e+07, 1.6679e+07, 1.8653e+07], device='cuda:0'),\n",
       " tensor([18860952., 19184276., 18698860., 46599400., 46643224., 25550148.,\n",
       "         25781914., 25773074., 25954396., 25934088., 23079176., 23168144.,\n",
       "         23616194., 18726294., 18828190., 18932680.], device='cuda:0'),\n",
       " tensor([18338384., 18630568., 56830200., 57324084., 56037904., 40440044.,\n",
       "         41251344., 41957784., 40375184., 40817132., 40863160., 46335304.,\n",
       "         46845856., 48002852., 47084548., 46288180.], device='cuda:0'),\n",
       " tensor([47507872., 13877214., 13718280., 13645110., 72718256., 71402224.,\n",
       "         73005824., 71911344., 72669592., 72971872., 73501904., 72753488.,\n",
       "         73563872., 72977200., 72264112., 72596272.], device='cuda:0'),\n",
       " tensor([7.2655e+07, 7.2911e+07, 3.5548e+07, 3.3726e+07, 3.5149e+07, 3.5135e+07,\n",
       "         1.3941e+08, 1.3803e+08, 1.3984e+08, 1.3990e+08, 1.3896e+08, 1.3996e+08,\n",
       "         9.2918e+06, 9.1822e+06, 8.9530e+06, 9.1907e+06], device='cuda:0'),\n",
       " tensor([2.1768e+08, 2.1951e+08, 2.2147e+08, 2.1355e+08, 2.1998e+08, 2.2598e+08,\n",
       "         2.2508e+08, 2.2609e+08, 2.2547e+08, 2.2774e+08, 2.7718e+08, 2.7623e+08,\n",
       "         2.2414e+08, 1.9259e+08, 2.2424e+08, 2.2321e+08], device='cuda:0'),\n",
       " tensor([2.2466e+08, 2.2182e+08, 2.5323e+08, 2.2446e+08, 2.1509e+08, 2.7583e+08,\n",
       "         2.7387e+08, 2.7341e+08, 2.2783e+08, 2.2791e+08, 2.3097e+08, 9.3252e+08,\n",
       "         9.2540e+08, 9.2587e+08, 9.1819e+08, 9.2390e+08], device='cuda:0'),\n",
       " tensor([9.1233e+08, 9.1744e+08, 9.4141e+08, 9.3672e+08, 9.1867e+08, 9.2557e+08,\n",
       "         5.2621e+08, 9.2406e+08, 9.4488e+08, 5.2398e+08, 5.2425e+08, 5.2029e+08,\n",
       "         5.2010e+08, 5.2211e+08, 5.1931e+08, 5.2302e+08], device='cuda:0'),\n",
       " tensor([5.1897e+08, 9.1553e+08, 5.1680e+08, 5.3144e+08, 5.2899e+08],\n",
       "        device='cuda:0')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_squared_error = torch.cat([values.flatten() for values in sum])\n",
    "total = torch.cat([values.flatten() for values in total])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  873.,   873.,   873.,  6498.,  6498.,  6498.,  6498.,  6498.,  6498.,\n",
       "         6498.,   333.,   333.,   333.,   333.,   333.,   762.,   762.,   762.,\n",
       "          762.,  1986.,  1986.,  1296.,  1296.,  1296.,  1296.,  1296.,  1248.,\n",
       "         1248.,  1248.,  1074.,  1074.,  1074.,  1074.,  1074.,  2481.,  2481.,\n",
       "         2481.,  2586.,  2586.,  2586.,  2586.,  2586.,  2586.,  1959.,  1959.,\n",
       "         1959.,  1959.,  1959.,  1959.,   741.,   741.,   741.,  3786.,  3786.,\n",
       "         3786.,  3786.,  3786.,  3786.,  3786.,  3786.,  3786.,  3786.,  3786.,\n",
       "         3786.,  3786.,  3786.,  1482.,  1482.,  1482.,  1482.,  7932.,  7932.,\n",
       "         7932.,  7932.,  7932.,  7932.,   492.,   492.,   492.,   492., 12003.,\n",
       "        12003., 12003.,  9849., 12003., 12498., 12498., 12498., 12003., 12498.,\n",
       "        14301., 14301., 12498., 11883., 12498., 12003., 12003., 12003., 11571.,\n",
       "        12003.,  9849., 14301., 14301., 14301., 12498., 12498., 12498., 46245.,\n",
       "        46245., 46245., 46245., 46245., 46245., 46245., 46245., 46245., 46245.,\n",
       "        46245., 32520., 46245., 46245., 32520., 32520., 32520., 32520., 32520.,\n",
       "        32520., 32520., 32520., 46245., 32520., 32520., 32520.],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9574e+07, 2.0267e+07, 1.9411e+07, 1.2925e+08, 1.2970e+08, 1.2852e+08,\n",
       "        1.3012e+08, 1.3009e+08, 1.2714e+08, 1.2911e+08, 1.6706e+07, 1.6516e+07,\n",
       "        1.6535e+07, 1.6470e+07, 1.6679e+07, 1.8653e+07, 1.8861e+07, 1.9184e+07,\n",
       "        1.8699e+07, 4.6599e+07, 4.6643e+07, 2.5550e+07, 2.5782e+07, 2.5773e+07,\n",
       "        2.5954e+07, 2.5934e+07, 2.3079e+07, 2.3168e+07, 2.3616e+07, 1.8726e+07,\n",
       "        1.8828e+07, 1.8933e+07, 1.8338e+07, 1.8631e+07, 5.6830e+07, 5.7324e+07,\n",
       "        5.6038e+07, 4.0440e+07, 4.1251e+07, 4.1958e+07, 4.0375e+07, 4.0817e+07,\n",
       "        4.0863e+07, 4.6335e+07, 4.6846e+07, 4.8003e+07, 4.7085e+07, 4.6288e+07,\n",
       "        4.7508e+07, 1.3877e+07, 1.3718e+07, 1.3645e+07, 7.2718e+07, 7.1402e+07,\n",
       "        7.3006e+07, 7.1911e+07, 7.2670e+07, 7.2972e+07, 7.3502e+07, 7.2753e+07,\n",
       "        7.3564e+07, 7.2977e+07, 7.2264e+07, 7.2596e+07, 7.2655e+07, 7.2911e+07,\n",
       "        3.5548e+07, 3.3726e+07, 3.5149e+07, 3.5135e+07, 1.3941e+08, 1.3803e+08,\n",
       "        1.3984e+08, 1.3990e+08, 1.3896e+08, 1.3996e+08, 9.2918e+06, 9.1822e+06,\n",
       "        8.9530e+06, 9.1907e+06, 2.1768e+08, 2.1951e+08, 2.2147e+08, 2.1355e+08,\n",
       "        2.1998e+08, 2.2598e+08, 2.2508e+08, 2.2609e+08, 2.2547e+08, 2.2774e+08,\n",
       "        2.7718e+08, 2.7623e+08, 2.2414e+08, 1.9259e+08, 2.2424e+08, 2.2321e+08,\n",
       "        2.2466e+08, 2.2182e+08, 2.5323e+08, 2.2446e+08, 2.1509e+08, 2.7583e+08,\n",
       "        2.7387e+08, 2.7341e+08, 2.2783e+08, 2.2791e+08, 2.3097e+08, 9.3252e+08,\n",
       "        9.2540e+08, 9.2587e+08, 9.1819e+08, 9.2390e+08, 9.1233e+08, 9.1744e+08,\n",
       "        9.4141e+08, 9.3672e+08, 9.1867e+08, 9.2557e+08, 5.2621e+08, 9.2406e+08,\n",
       "        9.4488e+08, 5.2398e+08, 5.2425e+08, 5.2029e+08, 5.2010e+08, 5.2211e+08,\n",
       "        5.1931e+08, 5.2302e+08, 5.1897e+08, 9.1553e+08, 5.1680e+08, 5.3144e+08,\n",
       "        5.2899e+08], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 10\n",
    "range = tensor(255)\n",
    "psnr_base_e = 2 * torch.log(range) - torch.log(sum_squared_error / total)\n",
    "psnr_vals = psnr_base_e * (10 / torch.log(tensor(base)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.6241, 4.4730, 4.6605, 5.1443, 5.1292, 5.1689, 5.1152, 5.1162, 5.2158,\n",
       "        5.1490, 1.1265, 1.1762, 1.1712, 1.1883, 1.1335, 4.2429, 4.1947, 4.1209,\n",
       "        4.2322, 4.4268, 4.4227, 5.1829, 5.1437, 5.1452, 5.1147, 5.1181, 5.4607,\n",
       "        5.4440, 5.3609, 5.7163, 5.6928, 5.6687, 5.8072, 5.7386, 4.5313, 4.4937,\n",
       "        4.5923, 6.1890, 6.1027, 6.0290, 6.1959, 6.1487, 6.1438, 4.3920, 4.3444,\n",
       "        4.2385, 4.3224, 4.3964, 4.2835, 5.4060, 5.4560, 5.4792, 5.2962, 5.3755,\n",
       "        5.2790, 5.3446, 5.2991, 5.2811, 5.2496, 5.2941, 5.2460, 5.2807, 5.3234,\n",
       "        5.3035, 5.3000, 5.2847, 4.3311, 4.5596, 4.3802, 4.3819, 5.6817, 5.7249,\n",
       "        5.6683, 5.6665, 5.6957, 5.6646, 5.3695, 5.4210, 5.5308, 5.4170, 5.5455,\n",
       "        5.5092, 5.4706, 4.7697, 5.4999, 5.5585, 5.5758, 5.5564, 5.3928, 5.5248,\n",
       "        5.2568, 5.2718, 5.5940, 6.0337, 5.5921, 5.4366, 5.4084, 5.4637, 4.7294,\n",
       "        5.4123, 4.7385, 5.2781, 5.3090, 5.3163, 5.5231, 5.5216, 5.4637, 5.0849,\n",
       "        5.1182, 5.1159, 5.1521, 5.1252, 5.1799, 5.1557, 5.0437, 5.0654, 5.1499,\n",
       "        5.1174, 6.0407, 5.1244, 5.0277, 6.0592, 6.0569, 6.0899, 6.0914, 6.0747,\n",
       "        6.0980, 6.0671, 6.1009, 5.1647, 6.1191, 5.9978, 6.0178],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psnr_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.1309, device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(psnr_vals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
