{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "os.environ['TORCH_HOME'] = '/root/data/torch_home'\n",
    "\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATASETS = os.path.join(os.environ.get(\"TORCH_HOME\", \".\"),\"mnist\")\n",
    "AVAIL_GPUS = min(1,torch.cuda.device_count())\n",
    "BATCH_SIZE = 256 if AVAIL_GPUS else 64 \n",
    "NUM_WORKERS = int(os.cpu_count()/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir : str = PATH_DATASETS,\n",
    "        batch_size : int = BATCH_SIZE,\n",
    "        num_workers : int = NUM_WORKERS \n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers \n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.1307,],[0.3081])\n",
    "        ])\n",
    "\n",
    "        # self.dims = (1, 28, 28)\n",
    "        self.num_classes = 10\n",
    "    \n",
    "    def prepare_data(self) -> None:\n",
    "        MNIST(self.data_dir, train = True, download=False)\n",
    "        MNIST(self.data_dir, train = False, download=False)\n",
    "        return super().prepare_data() \n",
    "\n",
    "    def setup(self, stage: Optional[str] = None) -> None:\n",
    "        if stage == 'fit' or stage is None:\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000,5000])\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=self.batch_size, num_workers = self.num_workers ) \n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=self.batch_size, num_workers=self.num_workers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_shape):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.img_shape = img_shape \n",
    "        def block(in_channels, out_channels, normalize=True):\n",
    "            layers = [nn.Linear(in_channels, out_channels)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_channels, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers \n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),\n",
    "            *block(128,256),\n",
    "            *block(256,512),\n",
    "            *block(512,1024),\n",
    "            nn.Linear(1024,int(np.prod(img_shape))),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0),*self.img_shape)\n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_shape):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)),512),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256,1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.rand(64)\n",
    "latent_dim = 100\n",
    "z = torch.rand(3,latent_dim)\n",
    "g = Generator(latent_dim,img_shape=(256,256))\n",
    "img = g(z)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(256,256)\n",
    "D = Discriminator(img.shape[0])\n",
    "res = D(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(LightningModule): \n",
    "    def __init__(\n",
    "        self, \n",
    "        channels,\n",
    "        width,\n",
    "        height,\n",
    "        latent_dim: int = 100,\n",
    "        lr:float = 0.0002,\n",
    "        b1: float = 0.5,\n",
    "        b2: float = 0.9999,\n",
    "        batch_size: int = BATCH_SIZE,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # networks \n",
    "        data_shape = (channels, width, height)\n",
    "        self.generator = Generator(latent_dim = self.hparams.latent_dim, img_shape = data_shape)\n",
    "        self.discriminator = Discriminator(img_shape=data_shape)\n",
    "        self.validation_z = torch.randn(8, self.hparams.latent_dim)\n",
    "        self.example_input_array = torch.zeros(2, self.hparams.latent_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.generator(z)\n",
    "    \n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        return F.binary_cross_entropy(y_hat, y)\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        imgs, _ = batch\n",
    "        # sample noise\n",
    "        z = torch.randn(imgs.shape[0], self.hparams.latent_dim)\n",
    "        z = z.type_as(imgs)\n",
    "\n",
    "        # train generator\n",
    "        if optimizer_idx == 0:\n",
    "            # generator images \n",
    "            self.generated_imgs = self(z)\n",
    "\n",
    "            # log sampled images\n",
    "            sample_imgs = self.generated_imgs[:6]\n",
    "            grid = torchvision.utils.make_grid(sample_imgs)\n",
    "            self.logger.experiment.add_image(\"generated_images\", grid, 0)\n",
    "\n",
    "            # ground truth result \n",
    "            # put on GPU \n",
    "            valid = torch.ones(imgs.size(0), 1)\n",
    "            valid = valid.type_as(imgs)\n",
    "\n",
    "            # adversarial loss\n",
    "            g_loss = self.adversarial_loss(self.discriminator(self(z)), valid)\n",
    "\n",
    "            tqdm_dict = {\"g_loss\":g_loss}\n",
    "            output = OrderedDict({\"loss\":g_loss, \"progress_bar\": tqdm_dict, \"log\":tqdm_dict})\n",
    "            return output\n",
    "\n",
    "        # train discriminator\n",
    "        if optimizer_idx == 1:\n",
    "            # Measure discriminator's ability to classify real from generated samples\n",
    "\n",
    "            # how well can it label as real?\n",
    "            valid = torch.ones(imgs.size(0), 1)\n",
    "            valid = valid.type_as(imgs)\n",
    "\n",
    "            real_loss = self.adversarial_loss(self.discriminator(imgs), valid)\n",
    "\n",
    "            # hwo well can it label as fake?\n",
    "\n",
    "            fake = torch.zeros(imgs.size(0), 1)\n",
    "            fake = fake.type_as(imgs)\n",
    "\n",
    "            fake_loss = self.adversarial_loss(self.discriminator(self(z).detach()), fake)\n",
    "\n",
    "            # discriminator loss is the average of these \n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            tqdm_dict = {\"d_loss\":d_loss}\n",
    "            output = OrderedDict({\"loss\": d_loss, \"progress_bar\": tqdm_dict, \"log\": tqdm_dict})\n",
    "            return output\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        lr = self.hparams.lr\n",
    "        b1 = self.hparams.b1\n",
    "        b2 = self.hparams.b2 \n",
    "\n",
    "        opt_g = torch.optim.Adam(self.generator.parameters(), lr = lr, betas = (b1, b2))\n",
    "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr = lr, betas=(b1, b2))\n",
    "        \n",
    "        return [opt_g, opt_d], []\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        z = self.validation_z.type_as(self.generator.model[0].weight)\n",
    "\n",
    "        # log sampled images \n",
    "        sample_imgs = self(z)\n",
    "        grid = torchvision.utils.make_grid(sample_imgs)\n",
    "        self.logger.experiment.add_image(\"generated_images\", grid, self.current_epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = MNISTDataModule()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GAN(*(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/root/data/venv/v_ptl/lib/python3.6/site-packages/pytorch_lightning/core/datamodule.py:470: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  f\"DataModule.{name} has already been called, so it will not be called again. \"\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name          | Type          | Params | In sizes | Out sizes     \n",
      "----------------------------------------------------------------------------\n",
      "0 | generator     | Generator     | 1.5 M  | [2, 100] | [2, 1, 28, 28]\n",
      "1 | discriminator | Discriminator | 533 K  | ?        | ?             \n",
      "----------------------------------------------------------------------------\n",
      "2.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 M     Total params\n",
      "8.174     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 215/215 [00:09<00:00, 21.59it/s, loss=2.69, v_num=13] \n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(gpus=AVAIL_GPUS, max_epochs= 5, progress_bar_refresh_rate=20)\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 18606 (pid 25027), started 0:00:14 ago. (Use '!kill 25027' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-78389a0a02420c2b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-78389a0a02420c2b\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 18606;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/ --port 18606"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fb5282727ef589ee08e59e7fc6ea9ada23c9eeb7c59a41ae982e41a853ca09f5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
